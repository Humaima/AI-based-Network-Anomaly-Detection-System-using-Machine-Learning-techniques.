# -*- coding: utf-8 -*-
"""AI Based Network Anomaly Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R5MuVcS_o47Nk-R0o0LvCeJGhDurG3Sf
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

train_data = '/content/drive/MyDrive/dataset/UNSW_NB15_training-set.csv'
train = pd.read_csv(train_data)

print('The train dataset contains {0} entries and {1} features'.format(*train.shape))

test_data = '/content/drive/MyDrive/dataset/UNSW_NB15_testing-set.csv'
test = pd.read_csv(test_data)

print('The test dataset contains {0} entries and {1} features'.format(*test.shape))

# preview train data
train.head()

train.columns

# Check for missing values
df = pd.concat([train,test]).drop('id',axis=1)
df = df.reset_index(drop=True)
print(df.isnull().sum().sum())

attack_counts = df['attack_cat'].value_counts()
(attack_counts / len(df)) * 100

Labels_in_df = df['attack_cat'].unique()
df['attack_cat'].value_counts().plot(kind='bar',figsize=(6,6))
df['attack_cat'].value_counts()

df.info()

for col in ['proto', 'service', 'state']:
    df[col] = df[col].astype('category').cat.codes

df['attack_cat'] = df['attack_cat'].astype('category')

from sklearn.model_selection import train_test_split

X = df.drop(columns = ['attack_cat', 'label'])
y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

feature_names = list(X.columns)

print("X_train shape: ", X_train.shape)
print("y_train shape: ", y_train.shape)
print("X_test shape: ", X_test.shape)
print("y_test shape: ", y_test.shape)

X_test = X_test.reset_index(drop=True)

rules= "(sttl <= 61.00 & sinpkt<= 0.00) | (sttl >  61.00 )"

ind = X_test.query(rules).index

X_test_2 = X_test.loc[ind,:]
y_test_2 = y_test[ind]

print(X_test.shape)
print(X_test_2.shape)
print("filtered data" , (1- np.round(X_test_2.shape[0] / X_test.shape[0],2))*100, "%")

from sklearn.metrics import accuracy_score, precision_score

def model_evaluation(model):
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test_2)

    accuracy = accuracy_score(y_test_2, y_pred)
    recall = recall_score(y_test_2, y_pred)
    precision = precision_score(y_test_2, y_pred)
    print("Recall: ", recall)
    print("Precision: ", precision)
    print("Accuracy: ", accuracy)

    cross = pd.crosstab(pd.Series(y_test_2, name='Actual'), pd.Series(y_pred, name='Predicted'))
    plt.figure(figsize=(5, 5))
    sns.heatmap(cross, annot=True,fmt='d', cmap="YlGnBu")
    plt.show()

    return {'Recall' : recall}

results = {}

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=11)

results['Random Forest Model'] = model_evaluation(rf)

from lightgbm import LGBMClassifier
lgbc = LGBMClassifier()
results['Light GBM Classifier'] = model_evaluation(lgbc)

comparision = pd.DataFrame(results)
comparision

feature_imp = pd.DataFrame({'Name':X.columns, 'Importance':rf.feature_importances_})

feature_imp = feature_imp.sort_values('Importance',ascending=False).reset_index(drop=True)

feature_imp[:10].style.background_gradient()

feat_importances = pd.Series(rf.feature_importances_, index=X.columns)
feat_importances.nlargest(20).plot(kind='bar',color=['r','g']*5)
plt.show()

top5= feature_imp.Name[:5].tolist()
top5

X = df[top5]
y = df['label'].values

rf_top10 = RandomForestClassifier(random_state=123)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)

rf_top10.fit(X_train, y_train)

y_pred = rf_top10.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print("Accuracy: ", acc)

top10= feature_imp.Name[:5].tolist()

X = df.loc[:, df.columns.isin(top10)]

y = df['attack_cat'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)

rf = RandomForestClassifier(random_state=11,min_samples_leaf= 1, min_samples_split= 5, n_estimators= 100)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print("Accuracy: ", acc)

# results['Random Forest Model Attack_cat'] = model_evaluation(rf)

cross = pd.crosstab(y_test,  y_pred)
plt.figure(figsize=(10, 10))
sns.heatmap(cross, annot=True,fmt='d', cmap="YlGnBu")
plt.show()

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import joblib
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, recall_score, precision_score

# Load datasets
train_data = '/content/drive/MyDrive/dataset/UNSW_NB15_training-set.csv'
test_data = '/content/drive/MyDrive/dataset/UNSW_NB15_testing-set.csv'

# Read the datasets
train = pd.read_csv(train_data)
test = pd.read_csv(test_data)

# Combine train and test for preprocessing
df = pd.concat([train, test]).drop('id', axis=1).reset_index(drop=True)

# Check for missing values
print(f"Missing values: {df.isnull().sum().sum()}")

# Define feature set for anomaly detection
features = ['proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate']
# Attack category names
attack_category_names = df['attack_cat'].astype('category').cat.categories.tolist()

# Split data into features and labels for label and attack category predictions
X = df[features]
y_label = df['label'].values  # Binary label (0: Normal, 1: Attack)
y_attack_cat = df['attack_cat'].astype('category').cat.codes  # Convert attack categories to numerical

# Train-test split
X_train_label, X_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.3, random_state=11)
X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X, y_attack_cat, test_size=0.3, random_state=11)

# Define the ColumnTransformer with OneHotEncoder to handle unknown categories
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['proto', 'service', 'state']),
        ('num', StandardScaler(), ['spkts', 'dpkts', 'sbytes', 'dbytes', 'rate'])
    ]
)

# Function for model evaluation
def model_evaluation(model, X_train, y_train, X_test, y_test, model_name):
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    pipeline.fit(X_train, y_train)

    y_pred = pipeline.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred, average='macro')
    precision = precision_score(y_test, y_pred, average='macro')

    print(f"{model_name} - Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}")

    # Confusion matrix
    cross = pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted'))
    plt.figure(figsize=(5, 5))
    sns.heatmap(cross, annot=True, fmt='d', cmap="YlGnBu")
    plt.title(f"{model_name} Confusion Matrix")
    plt.show()

    return pipeline

# Random Forest Model for label and attack category prediction
rf_label_model = model_evaluation(RandomForestClassifier(random_state=11), X_train_label, y_train_label, X_test_label, y_test_label, 'Random Forest - Label')
rf_cat_model = model_evaluation(RandomForestClassifier(random_state=11), X_train_cat, y_train_cat, X_test_cat, y_test_cat, 'Random Forest - Attack Category')

# Save the Random Forest models
joblib.dump(rf_label_model, 'rf_label_model.pkl')
joblib.dump(rf_cat_model, 'rf_cat_model.pkl')

print("Models saved!")

# Test cases for prediction
test_case = X_test_label.iloc[:5, :]  # First 5 samples from the test set for label and attack category predictions

# Predict labels (normal vs attack)
label_predictions_rf = rf_label_model.predict(test_case)
print("Test Case Predictions - Random Forest Label (0: Normal, 1: Attack):", label_predictions_rf)

# Predict attack categories and map them to attack category names
cat_predictions_rf = rf_cat_model.predict(test_case)
cat_predictions_rf_names = [attack_category_names[cat] for cat in cat_predictions_rf]
print("Test Case Predictions - Random Forest Attack Category Names:", cat_predictions_rf_names)